{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcor (x,y):\n",
    "    from scipy.stats import pearsonr\n",
    "    non_nan_indices = ~np.isnan(x) & ~np.isnan(y)\n",
    "    xx = x[non_nan_indices]\n",
    "    yy = y[non_nan_indices]\n",
    "    corr = pearsonr(xx,yy)\n",
    "    \n",
    "    # bad = ~np.logical_or(np.isnan(x), np.isnan(y))\n",
    "    #xx = np.compress(bad, x)  \n",
    "    #yy = np.compress(bad, y) \n",
    "    \n",
    "    corr, pvalue = pearsonr(xx, yy)  # Unpack both values here\n",
    "    return corr, pvalue\n",
    "   \n",
    "\n",
    "def clean_corr(x,y,n_mad=2):\n",
    "    x[pd.isna(x)]=x.min()#0\n",
    "    y[pd.isna(y)]=y.min()#0\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    if not isinstance(n_mad, str):\n",
    "        x_mad = stats.median_abs_deviation(x[x>x.min()],nan_policy='omit')\n",
    "        x_med = np.nanmedian(x[x>x.min()])\n",
    "        y_mad = stats.median_abs_deviation(y[y>y.min()],nan_policy='omit')\n",
    "        y_med = np.nanmedian(y[y>y.min()])\n",
    "        valid_ind = ((x<(x_med+(n_mad*x_mad))) & (x>(x_med-(n_mad*x_mad))) & (y<(y_med+(n_mad*y_mad))) & (y>(y_med-(n_mad*y_mad))) & (x>x.min()) & (y>y.min()))\n",
    "    else:\n",
    "        valid_ind = ((x>np.nanmin(x)) & (y>np.nanmin(y)))\n",
    "    \n",
    "    return stats.pearsonr(x[valid_ind], y[valid_ind])\n",
    "###>!!!!filter_plot_joint(external_datasets['expansion']['data'][:180],metric2mmp(all_avg_roi_vals,y_var,'roi_id'),xlabel='Brain expansion',ylabel=ylabel,n_mad='min')\n",
    "\n",
    "\n",
    "\n",
    "def threshold_proportional(W, p, copy=True):\n",
    "    '''\n",
    "    This function \"thresholds\" the connectivity matrix by preserving a\n",
    "    proportion p (0<p<1) of the strongest weights. All other weights, and\n",
    "    all weights on the main diagonal (self-self connections) are set to 0.\n",
    "    If copy is not set, this function will *modify W in place.*\n",
    "    Inputs: W,      weighted or binary conneccivity matrix\n",
    "            p,      proportion of weights to preserve\n",
    "                        range:  p=1 (all weights preserved) to\n",
    "                                p=0 (nco weights preserved)\n",
    "            copy,    copy W to avoid side effects, defaults to True\n",
    "    Output: W,        thresholded connectivity matrix\n",
    "    Note: The proportion of elements set to 0 is a fraction of all elements in the \n",
    "    matrix, whether or not they are already 0. That is, this function has the\n",
    "    following behavior:\n",
    "        >> x = np.random.random((10,10))\n",
    "        >> x_25 = threshold_proportional(x, .25)\n",
    "        >> np.size(np.where(x_25)) #note this double counts each nonzero element\n",
    "        46\n",
    "        >> x_125 = threshold_proportional(x, .125)\n",
    "        >> np.size(np.where(x_125))\n",
    "        22\n",
    "        >> x_test = threshold_proportional(x_25, .5)\n",
    "        >> np.size(np.where(x_test))\n",
    "        46\n",
    "    That is, the 50% thresholding of x_25 does nothing because >=50% of the elements\n",
    "    in x_25 are aleady <=0. This behavior is the same as in BCT. Be careful with matrices that are both signed and sparse.\n",
    "    '''\n",
    "    if p > 1 or p < 0:\n",
    "        raise BCTParamError('Threshold must be in range [0,1]')\n",
    "    if copy:\n",
    "        W = W.copy()\n",
    "    n = len(W)                        # number of nodes\n",
    "    np.fill_diagonal(W, 0)            # clear diagonal\n",
    "\n",
    "    if np.all(W == W.T):                # if symmetric matrix\n",
    "        W[np.tril_indices(n)] = 0        # ensure symmetry is preserved\n",
    "        ud = 2                        # halve number of removed links\n",
    "    else:\n",
    "        ud = 1\n",
    "\n",
    "    ind = np.where(W)                    # find all links\n",
    "\n",
    "    I = np.argsort(W[ind])[::-1]        # sort indices by magnitude\n",
    "\n",
    "    # number of links to be preserved\n",
    "    en = round((n * n - n) * p / ud)\n",
    "\n",
    "    W[(ind[0][I][en:], ind[1][I][en:])] = 0    # apply threshold\n",
    "\n",
    "    if ud == 2:                          # if symmetric matrix\n",
    "        W[:, :] = W + W.T                        # reconstruct symmetry\n",
    "\n",
    "    return W\n",
    "\n",
    "def only_IC_avg(FCmat, pet, SCmat, thr_sc, thr_FC, sub_size, scmask, nrois_rem):   \n",
    "    \n",
    "    SCmat_th = np.zeros((SCmat.shape[0], SCmat.shape[1], sub_size))\n",
    "    for i in range(sub_size):\n",
    "        SCmat_th[:, :, i] = threshold_proportional(SCmat[:, :, i], thr_sc)\n",
    "\n",
    "    SC_mask = SCmat_th.copy()\n",
    "    SC_mask[SC_mask > 0] = 1\n",
    "\n",
    "\n",
    "    FCmat_SC = np.multiply(FCmat , SC_mask)\n",
    "\n",
    "\n",
    "    pet_rem = pet.copy()\n",
    "\n",
    "    ICallsub_w = np.zeros((nrois_rem, sub_size))\n",
    "\n",
    "    for j in range(sub_size):\n",
    "        FCconn = FCmat_SC[:, :, j]\n",
    "        CMR2 = pet_rem[:, j]\n",
    "        FCconn_th = threshold_proportional(FCconn, thr_FC)\n",
    "        E_MAT = np.tile(CMR2, (nrois_rem, 1)) #########\n",
    "\n",
    "        \n",
    "\n",
    "        #row_sums = np.sum(FCconn_th, axis=1)  # Compute the sum of each row\n",
    "       # FCconn_thnor = FCconn_th / row_sums[:, np.newaxis]  # Divide each element by the corresponding row sum\n",
    "     \n",
    "        \n",
    "        row_sums = np.nansum(FCconn_th, axis=1)  # Compute the sum of each row\n",
    "        FCconn_thnor = np.divide(FCconn_th, row_sums[:, np.newaxis], out=np.zeros_like(FCconn_th), where=row_sums[:, np.newaxis] != 0)\n",
    "\n",
    "        # FCconn_thnor = np.zeros((nrois_rem, nrois_rem))\n",
    "       \n",
    "\n",
    "       # for r in range(nrois_rem):\n",
    "          #  for s in range(nrois_rem):\n",
    "           #     FCconn_thnor[r, s] = np.divide(FCconn_th[r, s] , np.nansum(FCconn_th[r, :]))\n",
    "                \n",
    "        \n",
    "        IC_w = np.nansum(np.multiply(FCconn_thnor , E_MAT), axis=1)\n",
    "\n",
    "        ICallsub_w[:, j] = IC_w\n",
    "\n",
    "    ICallsub_w[ICallsub_w == 0] = np.nan\n",
    "    ICallsub_w_avg = np.nanmean(ICallsub_w, axis=1)\n",
    "    \n",
    "    return ICallsub_w_avg\n",
    "\n",
    "def IC_calculation(FCmat, pet, SCmat, thr_sc, thr_FC, sub_size, scmask, nrois_rem):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    data_single_sub = {\n",
    "        'ICallsub_w': np.zeros((nrois_rem, sub_size)),\n",
    "        'ICallsub_b': np.zeros((nrois_rem, sub_size)),\n",
    "        'degallsub_w': np.zeros((nrois_rem, sub_size)),\n",
    "        'degallsub_b': np.zeros((nrois_rem, sub_size)),\n",
    "        'AvgMIallsub': np.zeros((nrois_rem, sub_size)),\n",
    "        'eig_cenallsub': np.zeros((nrois_rem, sub_size)),\n",
    "        'btw_cenallsub': np.zeros((nrois_rem, sub_size)),\n",
    "    }\n",
    "    \n",
    "    SCmat_th = np.zeros((SCmat.shape[0], SCmat.shape[1], sub_size))\n",
    "   \n",
    "    for i in range(sub_size):\n",
    "        SCmat_th[:, :, i] = threshold_proportional(SCmat[:, :, i], thr_sc)\n",
    "\n",
    "    SC_mask = SCmat_th.copy()\n",
    "    SC_mask[SC_mask > 0] = 1\n",
    "\n",
    "    \n",
    "\n",
    "    pet_rem = pet.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    for j in range(sub_size):\n",
    "        \n",
    "        FCconn = FCmat[:, :, j]\n",
    "        SCconn = SC_mask[:,:,j]\n",
    "        \n",
    "        \n",
    "        \n",
    "        FCconn_th = threshold_proportional(FCconn, thr_FC)\n",
    "        \n",
    "        # fc_neighbor_mask = connectivity_matrix_allsub[:, :, j]\n",
    "        # FCconn_th = FCconn_th * fc_neighbor_mask\n",
    "        \n",
    "        if scmask == 1:\n",
    "            FCmat_SC = np.multiply(FCconn_th , SCconn)\n",
    "        \n",
    "        else:\n",
    "            FCmat_SC = FCconn_th\n",
    "        CMR2 = pet_rem[:, j]\n",
    "        \n",
    "        #FCconn_th = FCconn\n",
    "        deg_w = np.nansum(FCmat_SC, axis=1)\n",
    "        FCconn_th_b = FCmat_SC.copy()\n",
    "        FCconn_th_b[FCconn_th_b > 0] = 1\n",
    "        deg_b = np.nansum(FCconn_th_b, axis=1)\n",
    "        E_MAT = np.tile(CMR2, (nrois_rem, 1)) #########\n",
    "        \n",
    "        \n",
    "        GFC = nx.Graph(FCmat_SC)\n",
    "        \n",
    "        #eigenvector_centrality = nx.eigenvector_centrality(GFC)\n",
    "        #eig_cen = list(eigenvector_centrality.values())\n",
    "        \n",
    "        betweenness_centrality = nx.betweenness_centrality(GFC , normalized=True, weight = 'weight')\n",
    "        btw_cen = list(betweenness_centrality.values())\n",
    "\n",
    "        #FCconn_thnor = np.zeros((nrois_rem, nrois_rem))\n",
    "        #FCconn_thnor_b = np.zeros((nrois_rem, nrois_rem))\n",
    "\n",
    "       # for r in range(nrois_rem):\n",
    "          #  for s in range(nrois_rem):\n",
    "              #  FCconn_thnor[r, s] = np.divide(FCconn_th[r, s] , np.nansum(FCconn_th[r, :]))\n",
    "               # FCconn_thnor_b[r, s] = np.divide(FCconn_th_b[r, s]  , np.nansum(FCconn_th_b[r, :]))\n",
    "                \n",
    "        row_sums = np.nansum(FCmat_SC, axis=1)  # Compute the sum of each row\n",
    "        FCconn_thnor = np.divide(FCmat_SC , row_sums[:, np.newaxis], out=np.zeros_like(FCmat_SC ), where=row_sums[:, np.newaxis] != 0)\n",
    "\n",
    "        row_sums_b = np.nansum(FCconn_th_b, axis=1)  # Compute the sum of each row\n",
    "        FCconn_thnor_b = np.divide(FCconn_th_b, row_sums_b[:, np.newaxis], out=np.zeros_like(FCconn_th_b), where=row_sums[:, np.newaxis] != 0)\n",
    "\n",
    "        IC_w = np.nansum(np.multiply(FCconn_thnor , E_MAT), axis=1)\n",
    "        IC_b = np.nansum(np.multiply(FCconn_thnor_b ,E_MAT), axis=1)\n",
    "        AvgMI = np.divide(deg_w , deg_b)\n",
    "\n",
    "        data_single_sub['ICallsub_w'][:, j] = IC_w\n",
    "        data_single_sub['ICallsub_b'][:, j] = IC_b\n",
    "        data_single_sub['degallsub_w'][:, j] = deg_w\n",
    "        data_single_sub['degallsub_b'][:, j] = deg_b\n",
    "        data_single_sub['AvgMIallsub'][:, j] = AvgMI\n",
    "        #data_single_sub['eig_cenallsub'][:, j] = eig_cen\n",
    "        data_single_sub['btw_cenallsub'][:, j] = btw_cen\n",
    "        \n",
    "\n",
    "    data_single_sub['ICallsub_w'][data_single_sub['ICallsub_w'] == 0] = np.nan\n",
    "    data_single_sub['ICallsub_b'][data_single_sub['ICallsub_b'] == 0] = np.nan\n",
    "    data_single_sub['degallsub_w'][data_single_sub['degallsub_w'] == 0] = np.nan\n",
    "    data_single_sub['degallsub_b'][data_single_sub['degallsub_b'] == 0] = np.nan\n",
    "    data_single_sub['AvgMIallsub'][data_single_sub['AvgMIallsub']== 0] = np.nan\n",
    "    #data_single_sub['eig_cenallsub'][data_single_sub['eig_cenallsub'] == 0] = np.nan\n",
    "    data_single_sub['btw_cenallsub'][data_single_sub['btw_cenallsub'] == 0] = np.nan\n",
    "    \n",
    "\n",
    "    degallsub_w_avg = np.nanmean(data_single_sub['degallsub_w'], axis=1)\n",
    "    degallsub_b_avg = np.nanmean(data_single_sub['degallsub_b'], axis=1)\n",
    "    pet_avg = np.nanmean(pet_rem, axis=1)\n",
    "    ICallsub_w_avg = np.nanmean(data_single_sub['ICallsub_w'], axis=1)\n",
    "    ICallsub_b_avg = np.nanmean(data_single_sub['ICallsub_b'], axis=1)\n",
    "    AvgMIallsub_avg = np.nanmean(data_single_sub['AvgMIallsub'], axis=1)\n",
    "    #eig_cenallsub_avg = np.nanmean(data_single_sub['eig_cenallsub'], axis=1)\n",
    "    btw_cenallsub_avg = np.nanmean(data_single_sub['btw_cenallsub'], axis=1)\n",
    "    \n",
    "    \n",
    "    data_avg = pd.DataFrame({'degallsub_w_avg' : degallsub_w_avg ,'degallsub_b_avg' : degallsub_b_avg,\n",
    "                       'pet_avg' : pet_avg , 'ICallsub_w_avg' : ICallsub_w_avg , \n",
    "                         'ICallsub_b_avg' : ICallsub_b_avg, 'AvgMIallsub_avg': AvgMIallsub_avg,  'btw_avg': btw_cenallsub_avg})#'eig_avg': eig_cenallsub_avg,\n",
    "        \n",
    "  \n",
    "    return data_avg, data_single_sub\n",
    "# def pcor (x,y):\n",
    "    \n",
    "#     bad = ~np.logical_or(np.isnan(x), np.isnan(y))\n",
    "#     xx = np.compress(bad, x)  \n",
    "#     yy = np.compress(bad, y)  \n",
    "#     corr = pearsonr(xx,yy)\n",
    "#     return corr\n",
    "\n",
    "\n",
    "def IC_within_btw_network(FCmat, pet, SCmat, thr_sc, thr_FC, sub_size, scmask, nrois_rem , net_label, net_names):\n",
    "    \n",
    "        \n",
    "    SCmat_th = np.zeros((SCmat.shape[0], SCmat.shape[1], sub_size))\n",
    "    for i in range(sub_size):\n",
    "        SCmat_th[:, :, i] = threshold_proportional(SCmat[:, :, i], thr_sc)\n",
    "\n",
    "    SC_mask = SCmat_th.copy()\n",
    "    SC_mask[SC_mask > 0] = 1\n",
    "\n",
    "    if scmask == 1:\n",
    "        FCmat_SC = np.multiply(FCmat , SC_mask)\n",
    "        \n",
    "    else:\n",
    "        FCmat_SC = FCmat\n",
    "\n",
    "    pet_rem = pet.copy()\n",
    "\n",
    "    ICallsub_wtn_w = np.zeros((nrois_rem, sub_size))\n",
    "    ICallsub_wtn_b = np.zeros((nrois_rem, sub_size))\n",
    "    \n",
    "    ICallsub_btw_w = np.zeros((nrois_rem, sub_size))\n",
    "    ICallsub_btw_b = np.zeros((nrois_rem, sub_size))\n",
    "    \n",
    "    degallsub_w = np.zeros((nrois_rem, sub_size))\n",
    "    degallsub_b = np.zeros((nrois_rem, sub_size))\n",
    "    \n",
    "    for j in range(sub_size):\n",
    "        FCconn = FCmat_SC[:, :, j]\n",
    "        CMR2 = pet_rem[:, j]\n",
    "        FCconn_th = threshold_proportional(FCconn, thr_FC)\n",
    "        #FCconn_th = FCconn\n",
    "        deg_w = np.nansum(FCconn_th, axis=1)\n",
    "        FCconn_th_b = FCconn_th.copy()\n",
    "        FCconn_th_b[FCconn_th_b > 0] = 1\n",
    "        deg_b = np.nansum(FCconn_th_b, axis=1)\n",
    "        E_MAT = np.tile(CMR2, (nrois_rem, 1)) #########\n",
    "\n",
    "        FCconn_thnor_wtn_net = np.zeros((nrois_rem, nrois_rem))\n",
    "        FCconn_thnor_b_wtn_net = np.zeros((nrois_rem, nrois_rem))\n",
    "        \n",
    "        FCconn_thnor_btw_net = np.zeros((nrois_rem, nrois_rem))\n",
    "        FCconn_thnor_b_btw_net = np.zeros((nrois_rem, nrois_rem))\n",
    "\n",
    "        IC_wtn_w = np.zeros((nrois_rem))\n",
    "        IC_wtn_b = np.zeros((nrois_rem))\n",
    "        \n",
    "        IC_btw_w = np.zeros((nrois_rem))\n",
    "        IC_btw_b = np.zeros((nrois_rem))\n",
    "        \n",
    "        for k in range(len(net_names)):\n",
    "            \n",
    "            ind = net_label[net_label['yeo_7_nw'].str.contains(net_names[k])].index\n",
    "            ind = ind.to_list()\n",
    "            complement = np.setdiff1d(np.arange(len(net_label)), ind)\n",
    "            \n",
    "            FCconn_th_wtn_net = np.zeros((nrois_rem, nrois_rem))\n",
    "            FCconn_th_wtn_net[ind , :] = FCconn_th[ind,:]\n",
    "            FCconn_th_wtn_net[: , ind] = FCconn_th_wtn_net[:,ind]\n",
    "            \n",
    "            FCconn_th_btw_net = np.zeros((nrois_rem, nrois_rem))\n",
    "            FCconn_th_btw_net[ind , :] = FCconn_th[ind , :]\n",
    "            FCconn_th_btw_net[: , complement] = FCconn_th_btw_net[: , complement]\n",
    "            \n",
    "            FCconn_th_b_wtn_net = np.zeros((nrois_rem, nrois_rem))\n",
    "            FCconn_th_b_wtn_net[ind , :] = FCconn_th[ind,:]\n",
    "            FCconn_th_b_wtn_net[: , ind] = FCconn_th_b_wtn_net[:,ind]\n",
    "            \n",
    "            FCconn_th_b_btw_net = np.zeros((nrois_rem, nrois_rem))\n",
    "            FCconn_th_b_btw_net[ind , :] = FCconn_th[ind , :]\n",
    "            FCconn_th_b_btw_net[: , complement] = FCconn_th_b_btw_net[: , complement]\n",
    "\n",
    "            \n",
    "            E_MAT_wtn_net = np.zeros((nrois_rem, nrois_rem))\n",
    "            E_MAT_wtn_net[ind , :] = E_MAT[ind,:]\n",
    "            E_MAT_wtn_net[: , ind] = E_MAT_wtn_net[:,ind]\n",
    "            \n",
    "            E_MAT_btw_net = np.zeros((nrois_rem, nrois_rem))\n",
    "            E_MAT_btw_net[ind , :] = E_MAT[ind , :]\n",
    "            E_MAT_btw_net[: , complement] = E_MAT_btw_net[: , complement]\n",
    "\n",
    "           \n",
    "            for r in ind:\n",
    "                for s in ind:\n",
    "                    \n",
    "                    FCconn_thnor_wtn_net[r, s] = np.divide(FCconn_th_wtn_net[r, s] , np.nansum(FCconn_th_wtn_net[r, :]))\n",
    "                    FCconn_thnor_b_wtn_net[r, s] = np.divide(FCconn_th_b_wtn_net[r, s]  , np.nansum(FCconn_th_b_wtn_net[r, :]))\n",
    "            \n",
    "            for r in range(len(ind)):\n",
    "                for s in range(len(complement)):\n",
    "\n",
    "                    FCconn_thnor_btw_net[r, s] = np.divide(FCconn_th_btw_net[r, s] , np.nansum(FCconn_th_btw_net[r, :]))\n",
    "                    FCconn_thnor_b_btw_net[r, s] = np.divide(FCconn_th_b_btw_net[r, s]  , np.nansum(FCconn_th_b_btw_net[r, :]))\n",
    "\n",
    "        \n",
    "\n",
    "                        \n",
    "            temp1 = np.nansum(np.multiply(FCconn_thnor_wtn_net , E_MAT_wtn_net), axis=1)\n",
    "            IC_wtn_w[ind] = temp1[ind]\n",
    "            temp2 = np.nansum(np.multiply(FCconn_thnor_b_wtn_net ,E_MAT_wtn_net), axis=1)\n",
    "            IC_wtn_b[ind] = temp2[ind]\n",
    "            \n",
    "            \n",
    "            \n",
    "            temp3 = np.nansum(np.multiply(FCconn_thnor_btw_net , E_MAT_btw_net), axis=1)\n",
    "            IC_btw_w[ind] = temp3[ind]\n",
    "            temp4 = np.nansum(np.multiply(FCconn_thnor_b_btw_net ,E_MAT_btw_net), axis=1)\n",
    "            IC_btw_b[ind] = temp4[ind]\n",
    "\n",
    "            \n",
    "            \n",
    "        ICallsub_btw_w[:, j] = IC_btw_w\n",
    "        ICallsub_btw_b[:, j] = IC_btw_b\n",
    "        \n",
    "        ICallsub_wtn_w[:, j] = IC_wtn_w\n",
    "        ICallsub_wtn_b[:, j] = IC_wtn_b\n",
    "        \n",
    "        degallsub_w[:, j] = deg_w\n",
    "        degallsub_b[:, j] = deg_b\n",
    "        \n",
    "\n",
    "    ICallsub_btw_w[ICallsub_btw_w == 0] = np.nan\n",
    "    ICallsub_btw_b[ICallsub_btw_b == 0] = np.nan\n",
    "    \n",
    "    ICallsub_wtn_w[ICallsub_wtn_w == 0] = np.nan\n",
    "    ICallsub_wtn_b[ICallsub_wtn_b == 0] = np.nan\n",
    "    \n",
    "    degallsub_w[degallsub_w == 0] = np.nan\n",
    "    degallsub_b[degallsub_b == 0] = np.nan\n",
    "    \n",
    "    degallsub_w_avg = np.nanmean(degallsub_w, axis=1)\n",
    "    degallsub_b_avg = np.nanmean(degallsub_b, axis=1)\n",
    "    pet_avg = np.nanmean(pet_rem, axis=1)\n",
    "    ICallsub_wtn_w_avg = np.nanmean(ICallsub_wtn_w, axis=1)\n",
    "    ICallsub_wtn_b_avg = np.nanmean(ICallsub_wtn_b, axis=1)\n",
    "    ICallsub_btw_w_avg = np.nanmean(ICallsub_btw_w, axis=1)\n",
    "    ICallsub_btw_b_avg = np.nanmean(ICallsub_btw_b, axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    data_avg = pd.DataFrame({'degallsub_w_avg' : degallsub_w_avg ,'degallsub_b_avg' : degallsub_b_avg,\n",
    "                       'pet_avg' : pet_avg , 'ICallsub_btw_w_avg' : ICallsub_btw_w_avg , \n",
    "                             'ICallsub_wtn_w_avg' : ICallsub_wtn_w_avg , 'ICallsub_wtn_b_avg' : ICallsub_wtn_b_avg , 'ICallsub_btw_b_avg' : ICallsub_btw_b_avg})\n",
    "        \n",
    "  \n",
    "    return data_avg, ICallsub_w, ICallsub_b, degallsub_w, degallsub_b  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IC_within_btw_network(FCmat,  SCmat, thr_sc, sub_size, scmask, nrois , net_label, net_names):\n",
    "    \n",
    "    num_net = len(net_names)  \n",
    "    SCmat_th = np.zeros((SCmat.shape[0], SCmat.shape[1], sub_size))\n",
    "    for i in range(sub_size):\n",
    "        SCmat_th[:, :, i] = threshold_proportional(SCmat[:, :, i], thr_sc)\n",
    "\n",
    "    SC_mask = SCmat_th.copy()\n",
    "    SC_mask[SC_mask > 0] = 1\n",
    "\n",
    "    if scmask == 1:\n",
    "        FCmat_SC = np.multiply(FCmat , SC_mask)\n",
    "        \n",
    "    else:\n",
    "        FCmat_SC = FCmat\n",
    "\n",
    "    \n",
    "    net_assign_allsub = np.zeros((nrois,num_net, sub_size))\n",
    "    \n",
    "    for i in range(sub_size):\n",
    "        \n",
    "        FC = FCmat_SC[:,:,i]\n",
    "        FC[FC>0] = 1\n",
    "        \n",
    "        net_num = net_label[\"network_number\"]\n",
    "        new_net_num = np.tile(net_num.transpose(), (nrois, 1)) \n",
    "        \n",
    "        FC_net = np.multiply(FC, new_net_num)\n",
    "        \n",
    "        \n",
    "        for r in range(nrois):\n",
    "            for s in range(num_net):\n",
    "                \n",
    "                net_assign_allsub[r,s,i] = np.sum(matrix[r] == s)\n",
    "                \n",
    "    \n",
    "    \n",
    "    entropy_allsub = np.zeros((nrois, sub_size))\n",
    "    \n",
    "    for i in range(sub_size):\n",
    "        net_assign = net_assign_allsub[:,:,i]\n",
    "        \n",
    "        conn_sum = np.sum(net_assign, axis=1)\n",
    "        probabilities = net_assign / conn_sum\n",
    "\n",
    "\n",
    "        entropy_allsub[:,i] = -np.sum(probabilities * np.log2(probabilities))\n",
    "        \n",
    "    \n",
    "    entropy_avg = np.mean(entropy_allsub , axis = 1)\n",
    "    \n",
    "    return entropy_allsub, entropy_avg\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID_calculation(FCmat, pet, SCmat, thr_sc, thr_FC, sub_size, scmask, nrois_rem):\n",
    "    data_single_sub = {\n",
    "        'ICallsub_w': np.zeros((nrois_rem, sub_size)),\n",
    "        'ICallsub_b': np.zeros((nrois_rem, sub_size)),\n",
    "        'degallsub_w': np.zeros((nrois_rem, sub_size)),\n",
    "        'degallsub_b': np.zeros((nrois_rem, sub_size)),\n",
    "        'AvgMIallsub': np.zeros((nrois_rem, sub_size)),\n",
    "        'eig_cenallsub': np.zeros((nrois_rem, sub_size)),\n",
    "        'btw_cenallsub': np.zeros((nrois_rem, sub_size)),\n",
    "    }\n",
    "    \n",
    "    SCmat_th = np.zeros((SCmat.shape[0], SCmat.shape[1], sub_size))\n",
    "    \n",
    "    for i in range(sub_size):\n",
    "        SCmat_th[:, :, i] = threshold_proportional(SCmat[:, :, i], thr_sc)\n",
    "\n",
    "    SC_mask = SCmat_th.copy()\n",
    "    SC_mask[SC_mask > 0] = 1\n",
    "\n",
    "    \n",
    "\n",
    "    pet_rem = pet.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    for j in range(sub_size):\n",
    "        \n",
    "        FCconn = FCmat[:, :, j]\n",
    "        SCconn = SC_mask[:,:,j]\n",
    "        \n",
    "        \n",
    "        \n",
    "        FCconn_th = threshold_proportional(FCconn, thr_FC)\n",
    "        \n",
    "        if scmask == 1:\n",
    "            FCmat_SC = np.multiply(FCconn_th , SCconn)\n",
    "        \n",
    "        else:\n",
    "            FCmat_SC = FCconn_th\n",
    "        CMR2 = pet_rem[:, j]\n",
    "        \n",
    "        #FCconn_th = FCconn\n",
    "        deg_w = np.nansum(FCmat_SC, axis=1)\n",
    "        FCconn_th_b = FCmat_SC.copy()\n",
    "        FCconn_th_b[FCconn_th_b > 0] = 1\n",
    "        deg_b = np.nansum(FCconn_th_b, axis=1)\n",
    "        E_MAT = np.tile(CMR2, (nrois_rem, 1)) #########\n",
    "        \n",
    "        \n",
    "        GFC = nx.Graph(FCmat_SC)\n",
    "        \n",
    "        eigenvector_centrality = nx.eigenvector_centrality(GFC)\n",
    "        eig_cen = list(eigenvector_centrality.values())\n",
    "        \n",
    "        betweenness_centrality = nx.betweenness_centrality(GFC , normalized=True, weight = 'weight')\n",
    "        btw_cen = list(betweenness_centrality.values())\n",
    "\n",
    "        #FCconn_thnor = np.zeros((nrois_rem, nrois_rem))\n",
    "        #FCconn_thnor_b = np.zeros((nrois_rem, nrois_rem))\n",
    "\n",
    "       # for r in range(nrois_rem):\n",
    "          #  for s in range(nrois_rem):\n",
    "              #  FCconn_thnor[r, s] = np.divide(FCconn_th[r, s] , np.nansum(FCconn_th[r, :]))\n",
    "               # FCconn_thnor_b[r, s] = np.divide(FCconn_th_b[r, s]  , np.nansum(FCconn_th_b[r, :]))\n",
    "                \n",
    "        row_sums = np.nansum(FCmat_SC, axis=1)  # Compute the sum of each row\n",
    "        #FCconn_thnor = np.divide(FCmat_SC , row_sums[:, np.newaxis], out=np.zeros_like(FCmat_SC ), where=row_sums[:, np.newaxis] != 0)\n",
    "        \n",
    "        FCconn_thnor = FCmat_SC \n",
    "        row_sums_b = np.nansum(FCconn_th_b, axis=1)  # Compute the sum of each row\n",
    "        FCconn_thnor_b = np.divide(FCconn_th_b, row_sums_b[:, np.newaxis], out=np.zeros_like(FCconn_th_b), where=row_sums[:, np.newaxis] != 0)\n",
    "\n",
    "        IC_w = np.nansum(np.multiply(FCconn_thnor , E_MAT), axis=1)\n",
    "        IC_b = np.nansum(np.multiply(FCconn_thnor_b ,E_MAT), axis=1)\n",
    "        AvgMI = np.divide(deg_w , deg_b)\n",
    "\n",
    "        data_single_sub['ICallsub_w'][:, j] = IC_w\n",
    "        data_single_sub['ICallsub_b'][:, j] = IC_b\n",
    "        data_single_sub['degallsub_w'][:, j] = deg_w\n",
    "        data_single_sub['degallsub_b'][:, j] = deg_b\n",
    "        data_single_sub['AvgMIallsub'][:, j] = AvgMI\n",
    "        data_single_sub['eig_cenallsub'][:, j] = eig_cen\n",
    "        data_single_sub['btw_cenallsub'][:, j] = btw_cen\n",
    "        data_single_sub['petallsub'][:, j] = pet_rem\n",
    "        \n",
    "        \n",
    "\n",
    "    data_single_sub['ICallsub_w'][data_single_sub['ICallsub_w'] == 0] = np.nan\n",
    "    data_single_sub['ICallsub_b'][data_single_sub['ICallsub_b'] == 0] = np.nan\n",
    "    data_single_sub['degallsub_w'][data_single_sub['degallsub_w'] == 0] = np.nan\n",
    "    data_single_sub['degallsub_b'][data_single_sub['degallsub_b'] == 0] = np.nan\n",
    "    data_single_sub['AvgMIallsub'][data_single_sub['AvgMIallsub']== 0] = np.nan\n",
    "    data_single_sub['eig_cenallsub'][data_single_sub['eig_cenallsub'] == 0] = np.nan\n",
    "    data_single_sub['btw_cenallsub'][data_single_sub['btw_cenallsub'] == 0] = np.nan\n",
    "    data_single_sub['petallsub'][data_single_sub['petallsub'] == 0] = np.nan\n",
    "    \n",
    "\n",
    "    degallsub_w_avg = np.nanmean(data_single_sub['degallsub_w'], axis=1)\n",
    "    degallsub_b_avg = np.nanmean(data_single_sub['degallsub_b'], axis=1)\n",
    "    pet_avg = np.nanmean(pet_rem, axis=1)\n",
    "    ICallsub_w_avg = np.nanmean(data_single_sub['ICallsub_w'], axis=1)\n",
    "    ICallsub_b_avg = np.nanmean(data_single_sub['ICallsub_b'], axis=1)\n",
    "    AvgMIallsub_avg = np.nanmean(data_single_sub['AvgMIallsub'], axis=1)\n",
    "    eig_cenallsub_avg = np.nanmean(data_single_sub['eig_cenallsub'], axis=1)\n",
    "    btw_cenallsub_avg = np.nanmean(data_single_sub['btw_cenallsub'], axis=1)\n",
    "    \n",
    "    \n",
    "    data_avg = pd.DataFrame({'degallsub_w_avg' : degallsub_w_avg ,'degallsub_b_avg' : degallsub_b_avg,\n",
    "                       'pet_avg' : pet_avg , 'ICallsub_w_avg' : ICallsub_w_avg , \n",
    "                         'ICallsub_b_avg' : ICallsub_b_avg, 'AvgMIallsub_avg': AvgMIallsub_avg, 'eig_avg': eig_cenallsub_avg, 'btw_avg': btw_cenallsub_avg})\n",
    "        \n",
    "  \n",
    "    return data_avg, data_single_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spatial_AC(DATA_avg, ic, LIMB,niter):\n",
    "    from scipy import stats\n",
    "\n",
    "    from brainsmash.mapgen.stats import pearsonr\n",
    "    if LIMB == \"without\":\n",
    "        dist_file = \"/data/external/LeftParcelGeodesicDistmat_wolimb.txt\"\n",
    "    else:\n",
    "        dist_file = \"data/external/LeftParcelGeodesicDistmat.txt\"\n",
    "        \n",
    "\n",
    "    ## ic can be IC or deg_w or deg_b: \n",
    "    \n",
    "            \n",
    "        \n",
    "    ## Contain the limbic network regions for SAC: \n",
    "\n",
    "    # load parcellated neuroimaging maps\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if ic == \"IC\":\n",
    "        half_size = len(DATA_avg.ICallsub_w_avg.values) // 2  \n",
    "        pet = DATA_avg.pet_avg.values[0:half_size]\n",
    "        IC = DATA_avg.ICallsub_w_avg.values[0:half_size]\n",
    "        \n",
    "        \n",
    "    elif ic == \"deg_w\":\n",
    "        \n",
    "        half_size = len(DATA_avg.ICallsub_w_avg.values) // 2 \n",
    "        IC = DATA_avg.degallsub_w_avg.values[0:half_size]\n",
    "        pet = DATA_avg.pet_avg.values[0:half_size]\n",
    "\n",
    "    elif ic == \"PC\":\n",
    "        \n",
    "        half_size = len(DATA_avg.ICallsub_w_avg.values) // 2 \n",
    "        IC = DATA_avg.PCallsub_w_avg.values[0:half_size]\n",
    "        pet = DATA_avg.pet_avg.values[0:half_size]\n",
    "        \n",
    "    elif ic == \"deg_b\":\n",
    "        \n",
    "        half_size = len(DATA_avg.ICallsub_w_avg.values) // 2 \n",
    "        IC = DATA_avg.degallsub_b_avg.values[0:half_size]\n",
    "        pet = DATA_avg.pet_avg.values[0:half_size]\n",
    "    else:\n",
    "        x_ser = DATA_avg['x']\n",
    "        y_ser = DATA_avg['y']\n",
    "        half_size = len(x_ser) // 2        \n",
    "        IC  = x_ser.to_numpy()[:half_size]\n",
    "        pet = y_ser.to_numpy()[:half_size]\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # instantiate class and generate 1000 surrogates\n",
    "    gen = Base(pet, dist_file) \n",
    "    surrogate_maps = gen(n = niter)\n",
    "\n",
    "\n",
    "    surrogate_brainmap_corrs = pearsonr(IC, surrogate_maps).flatten()\n",
    "    surrogate_pairwise_corrs = pairwise_r(surrogate_maps, flatten=True)\n",
    "\n",
    "    naive_surrogates = np.array([np.random.permutation(pet) for _ in range(niter)])\n",
    "    naive_brainmap_corrs = pearsonr(IC, naive_surrogates).flatten()\n",
    "    naive_pairwise_corrs = pairwise_r(naive_surrogates, flatten=True)\n",
    "    \n",
    "    sac = '#377eb8'  # autocorr-preserving\n",
    "    rc = '#e41a1c'  # randomly shuffled\n",
    "    bins = np.linspace(-1, 1, 51)  # correlation b\n",
    "\n",
    "    # this is the empirical statistic we're creating a null distribution for\n",
    "    test_stat = stats.pearsonr(pet, IC)[0]\n",
    "\n",
    "    base_fit(\n",
    "        x=pet,\n",
    "        D=dist_file,\n",
    "        nsurr= niter,\n",
    "        nh=25,  # these are default kwargs, but shown here for demonstration\n",
    "        deltas=np.arange(0.1, 1, 0.1),\n",
    "        pv=25)  # kwargs are passed to brainsmash.mapgen.base.Base\n",
    "\n",
    "    spatially_naive_p_value = nonparp(test_stat, naive_brainmap_corrs)\n",
    "    sa_corrected_p_value = nonparp(test_stat, surrogate_brainmap_corrs)\n",
    "    \n",
    "\n",
    "\n",
    "    test_stat = stats.pearsonr(pet, IC)[0]\n",
    "    print(\"Pearson correlation:\", test_stat)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Spatially naive p-value: {:.2e}\".format(spatially_naive_p_value))\n",
    "    print(\"SA-corrected p-value: {:.2e}\".format(sa_corrected_p_value))\n",
    "    \n",
    "    \n",
    "    return test_stat ,surrogate_brainmap_corrs, sa_corrected_p_value, spatially_naive_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gaussian copula mutual information estimation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "__version__ = '0.3'\n",
    "\n",
    "def ctransform(x):\n",
    "    \"\"\"Copula transformation (empirical CDF)\n",
    "    cx = ctransform(x) returns the empirical CDF value along the first\n",
    "    axis of x. Data is ranked and scaled within [0 1] (open interval).\n",
    "    \"\"\"\n",
    "\n",
    "    xi = np.argsort(np.atleast_2d(x))\n",
    "    xr = np.argsort(xi)\n",
    "    cx = (xr+1).astype(float) / (xr.shape[-1]+1)\n",
    "    return cx\n",
    " \n",
    "\n",
    "def copnorm(x):\n",
    "    \"\"\"Copula normalization\n",
    "    \n",
    "    cx = copnorm(x) returns standard normal samples with the same empirical\n",
    "    CDF value as the input. Operates along the last axis.\n",
    "    \"\"\"\n",
    "    cx = sp.stats.norm.ppf(ctransform(x))\n",
    "    #cx = sp.special.ndtri(ctransform(x))\n",
    "    return cx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mi_gg(x, y, biascorrect=True, demeaned=False):\n",
    "    \"\"\"Mutual information (MI) between two Gaussian variables in bits\n",
    "   \n",
    "    I = mi_gg(x,y) returns the MI between two (possibly multidimensional)\n",
    "    Gassian variables, x and y, with bias correction.\n",
    "    If x and/or y are multivariate columns must correspond to samples, rows\n",
    "    to dimensions/variables. (Samples last axis) \n",
    "                                                                             \n",
    "    biascorrect : true / false option (default true) which specifies whether\n",
    "    bias correction should be applied to the esimtated MI.\n",
    "    demeaned : false / true option (default false) which specifies whether th\n",
    "    input data already has zero mean (true if it has been copula-normalized)\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "    if x.ndim > 2 or y.ndim > 2:\n",
    "        raise ValueError(\"x and y must be at most 2d\")\n",
    "    Ntrl = x.shape[1]\n",
    "    Nvarx = x.shape[0]\n",
    "    Nvary = y.shape[0]\n",
    "    Nvarxy = Nvarx+Nvary\n",
    "\n",
    "    if y.shape[1] != Ntrl:\n",
    "        raise ValueError(\"number of trials do not match\")\n",
    "\n",
    "    # joint variable\n",
    "    xy = np.vstack((x,y))\n",
    "    if not demeaned:\n",
    "        xy = xy - xy.mean(axis=1)[:,np.newaxis]\n",
    "    Cxy = np.dot(xy,xy.T) / float(Ntrl - 1)\n",
    "    # submatrices of joint covariance\n",
    "    Cx = Cxy[:Nvarx,:Nvarx]\n",
    "    Cy = Cxy[Nvarx:,Nvarx:]\n",
    "\n",
    "    chCxy = np.linalg.cholesky(Cxy)\n",
    "    chCx = np.linalg.cholesky(Cx)\n",
    "    chCy = np.linalg.cholesky(Cy)\n",
    "\n",
    "    # entropies in nats\n",
    "    # normalizations cancel for mutual information\n",
    "    HX = np.sum(np.log(np.diagonal(chCx))) # + 0.5*Nvarx*(np.log(2*np.pi)+1.0)\n",
    "    HY = np.sum(np.log(np.diagonal(chCy))) # + 0.5*Nvary*(np.log(2*np.pi)+1.0)\n",
    "    HXY = np.sum(np.log(np.diagonal(chCxy))) # + 0.5*Nvarxy*(np.log(2*np.pi)+1.0)\n",
    "\n",
    "    ln2 = np.log(2)\n",
    "    if biascorrect:\n",
    "        psiterms = sp.special.psi((Ntrl - np.arange(1,Nvarxy+1)).astype(np.float)/2.0) / 2.0\n",
    "        dterm = (ln2 - np.log(Ntrl-1.0)) / 2.0\n",
    "        HX = HX - Nvarx*dterm - psiterms[:Nvarx].sum()\n",
    "        HY = HY - Nvary*dterm - psiterms[:Nvary].sum()\n",
    "        HXY = HXY - Nvarxy*dterm - psiterms[:Nvarxy].sum()\n",
    "\n",
    "    # MI in bits\n",
    "    I = (HX + HY - HXY) / ln2\n",
    "    return I\n",
    "\n",
    "\n",
    "\n",
    "def conn_mat_EI_new(data, nvox, nT, Parc1, GM, VOX, num_pcs, ABS, rem_ind):\n",
    "    \n",
    "    if VOX == 1:\n",
    "        \n",
    "        rem_ind = limb_ind;\n",
    "        Parcfmri_gm = np.multiply(Parc1 , GM)\n",
    "        #Parcfmri_gm = Parc1 \n",
    "        Parcfmri_gm_re = np.reshape(Parcfmri_gm, [nvox, 1],order='F')\n",
    "        parcindfmri_gm = np.unique(Parcfmri_gm_re)\n",
    "        parcindfmri_gm = parcindfmri_gm[1:]\n",
    "        nrois_gm = len(np.unique(Parcfmri_gm)) - 1\n",
    "\n",
    "        Parc1_re = np.reshape(Parc1, [nvox, 1],order='F')\n",
    "        nrois = len(np.unique(Parc1_re)) - 1\n",
    "        nrois_rem = nrois - len(rem_ind)\n",
    "        rois_remain = np.arange(1, nrois+1 )\n",
    "        rois_remain[limb_ind ] = 0  \n",
    "        rois_remain = rois_remain[rois_remain != 0] \n",
    "\n",
    "        data_re = np.reshape(data, [nvox, nT] ,order='F')\n",
    "        Parcindfmri = np.unique(Parc1)\n",
    "        Parcindfmri = Parcindfmri[1:]\n",
    "        DATA_avg = np.zeros([nT, nrois])\n",
    "        num_voxels = np.zeros((nrois))\n",
    "        DATA = {}\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(nrois):\n",
    "\n",
    "            if np.any(Parcfmri_gm_re == Parcindfmri[i]):\n",
    "\n",
    "                ind = np.where(Parcfmri_gm_re == Parcindfmri[i])[0]\n",
    "\n",
    "                dd = data_re[ind, :]\n",
    "\n",
    "                # indremove = np.where(np.all(dd == 0, axis=1))[0]\n",
    "                # dd = np.delete(dd, indremove, axis=0)\n",
    "\n",
    "                # if indremove.size == ind.size:\n",
    "                #     zero_rois[i] = 1\n",
    "\n",
    "                DATA[i] = dd\n",
    "                num_voxels[i] = dd.shape[0]\n",
    "                # edata_median[i, 0] = np.median(edata_re[ind])\n",
    "                DATA_avg[:, i] = np.mean(dd, axis=0)\n",
    "            else:\n",
    "                DATA_avg[:, i] = np.nan \n",
    "                DATA[i] = np.zeros((10,1)) \n",
    "\n",
    "        \n",
    "    else:\n",
    "        DATA_avg = data\n",
    "        #nrois = nvox\n",
    "       # nrois_rem = nrois - len(rem_ind)\n",
    "    \n",
    "    \n",
    "\n",
    "    Pearconn = np.corrcoef(DATA_avg, rowvar=False)\n",
    "    Pearconn = np.delete(Pearconn , rem_ind , axis =0)\n",
    "    Pearconn = np.delete(Pearconn , rem_ind , axis =1)\n",
    "\n",
    "    # MVMIconn = np.zeros((nrois_rem, nrois_rem))\n",
    "    MIconn = np.zeros((nrois_rem, nrois_rem))\n",
    "    cDATA_avg = np.transpose(copnorm(np.transpose(DATA_avg)))\n",
    "    np.delete(cDATA_avg, limb_ind)\n",
    "    zero_rois = np.zeros(nrois_rem)\n",
    "    Cdata_abs = {}\n",
    "    Cdata = {}\n",
    "    for i in range(nrois_rem):\n",
    "\n",
    "        X = DATA[ rois_remain[i]-1]\n",
    "        ind = np.where(np.sum(X, axis=0) == 0)[0]\n",
    "        if np.any(X) == True:\n",
    "            X = np.delete(X, ind, axis=0)\n",
    "        else:\n",
    "            zero_rois[i] = 1\n",
    "\n",
    "\n",
    "\n",
    "        quan = np.quantile(num_voxels, [0.25, 0.5, 0.75, 1])\n",
    "        if num_voxels[rois_remain[i]-1] > quan[2]:\n",
    "            num_pcs = 5\n",
    "        elif num_voxels[rois_remain[i]-1] > quan[1]:\n",
    "            num_pcs = 4\n",
    "        elif num_voxels[rois_remain[i]-1] > quan[0]:\n",
    "            num_pcs = 3\n",
    "        else:\n",
    "            num_pcs = 2\n",
    "\n",
    "\n",
    "        pca = PCA()\n",
    "        X_score = pca.fit_transform(np.transpose(X))\n",
    "        CC = copnorm(X_score[:, 0:min(num_pcs, X_score.shape[1])].T)\n",
    "        Cdata_abs[i] = np.hstack((CC, copnorm(np.abs(CC))))\n",
    "        Cdata[i] = CC\n",
    "\n",
    "    for i in range(nrois_rem):\n",
    "\n",
    "        if zero_rois[i]==1:\n",
    "            MIconn[i,:]=np.nan\n",
    "           # MVMIconn[i,:]=np.nan\n",
    "            continue\n",
    "\n",
    "        CX = Cdata[i]\n",
    "        CX2 = Cdata_abs[i]\n",
    "\n",
    "        for j in range(i+1, nrois_rem):\n",
    "\n",
    "            if zero_rois[j]==1:\n",
    "                MIconn[:,j]=np.nan\n",
    "                #MVMIconn[:,j]=np.nan\n",
    "                continue\n",
    "\n",
    "            MIconn[j,i]= mi_gg(cDATA_avg[:,rois_remain[j]-1],cDATA_avg[:,rois_remain[i]-1])  \n",
    "\n",
    "            CY = Cdata[j]     \n",
    "            CY2 = Cdata_abs[j]\n",
    "\n",
    "           # if ABS == 1:\n",
    "               # num = min(CX2.shape[1], CY2.shape[1])\n",
    "               # MVMIconn[i,j] = mi_gg(CX2[:, :num], CY2[:, :num])\n",
    "            #else:\n",
    "               # MVMIconn[i,j] = mi_gg(CX, CY)\n",
    "\n",
    "\n",
    "    MIconn = MIconn + MIconn.T\n",
    "    \n",
    "    \n",
    "            \n",
    "     \n",
    "    #MVMIconn = MVMIconn + MVMIconn.T\n",
    "\n",
    "    return num_voxels  , MIconn , Pearconn\n",
    "\n",
    "\n",
    "def IC_model(X):\n",
    "    E = X[:len(X)//2]\n",
    "    alpha = X[len(X)//2:]\n",
    "    IC = np.nansum(np.multiply(E,alpha))\n",
    "    return IC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional connectivity (MIconn , Pearconn, numvox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Functional_conn(DIR, session, sub, limb_ind, nrois):\n",
    "    \n",
    "    data_input = {}\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    #sub = [3,7,12,14,17,20,23,25,26,28,29,30,31,32,33,35,36,37,38]; \n",
    "    #sub = [3,7,12,14,17,20,23,25,26,28,29,30,31,33,35,36,37,38]; \n",
    "\n",
    "    #subcor = 15 #***with subcortical******\n",
    "    subcor = 0\n",
    "    remain_rois = range(0 , nrois)\n",
    "    remain_rois = np.delete(remain_rois , limb_ind)\n",
    "    nrois_rem = nrois - len(limb_ind)\n",
    "    mask_rois = np.zeros((nrois, len(sub)))\n",
    "    rois_remain = np.zeros((nrois_rem, len(sub)))\n",
    "\n",
    "    data_input['num_voxels'] = np.zeros((nrois, len(sub) ))\n",
    "    data_input['edata_medianallsub'] = np.zeros((nrois_rem, len(sub) ))\n",
    "    data_input['MVMIconn_allsub'] = np.zeros((nrois_rem, nrois_rem, len(sub)))\n",
    "    data_input['SCconn_allsub'] = np.zeros((nrois_rem, nrois_rem, len(sub) ))\n",
    "    data_input['Pearconn_allsub'] = np.zeros((nrois_rem, nrois_rem, len(sub) ))\n",
    "\n",
    "\n",
    "    for b ,subject in enumerate(sub):\n",
    "        \n",
    "        #loading the GM and parcellation in pet and fmri spaces\n",
    "\n",
    "        DIR1 = f'{DIR}sub-{subject:03}/'\n",
    "        Parcfmri =  nib.load(f'{DIR1}MMP_in_func3mm.nii.gz').get_fdata()\n",
    "        #Parcfmri_subcor =  40 * nib.load(DIR1 + 'mmp_subcortical_in_func3mm.nii.gz').get_fdata()\n",
    "        #Parcfmri_subcor_mask =  nib.load(DIR1 + 'mmp_subcortical_in_func3mm_mask.nii.gz').get_fdata()\n",
    "\n",
    "\n",
    "        Parcpet  =  nib.load(DIR1 + 'MMP_in_pet3mm.nii.gz').get_fdata()\n",
    "        #Parcpet_subcor  =  40 * nib.load(DIR1 + 'mmp_subcortical_in_pet3mm.nii.gz').get_fdata()\n",
    "        #Parcpet_subcor_mask =  nib.load(DIR1 + 'mmp_subcortical_in_pet3mm_mask.nii.gz').get_fdata()\n",
    "\n",
    "\n",
    "        GM_fmri  =  nib.load(DIR1 + \"gm_in_func3mm.nii.gz\").get_fdata()\n",
    "        GM_pet   =  nib.load(DIR1 + \"gm_in_pet3mm.nii.gz\").get_fdata()    \n",
    "\n",
    "\n",
    "        #for adding subcortical regions uncomment the 4 following lines:\n",
    "\n",
    "        #indic_func = -Parcfmri_subcor_mask+1\n",
    "        #indic_pet  = -Parcpet_subcor_mask+1\n",
    "        #Parcfmri  =   np.multiply(indic_func,Parcfmri) + Parcfmri_subcor #***with subcortical******\n",
    "        #Parcpet =  np.multiply(indic_pet , Parcpet)  + Parcpet_subcor #***with subcortical******\n",
    "       # GM_fmri =  GM_fmri + Parcfmri_subcor_mask #***with subcortical******\n",
    "        #GM_pet  =  GM_pet   + Parcpet_subcor_mask #***with subcortical******\n",
    "\n",
    "\n",
    "        #loading the fmri and pet data\n",
    "        BDATA = nib.load(DIR1 + 'func3mm.nii.gz').get_fdata()\n",
    "        EDATA = nib.load(DIR1 + 'pet3mm.nii.gz').get_fdata()\n",
    "\n",
    "        v1, v2, v3, v4 = BDATA.shape\n",
    "        nT = v4\n",
    "        nvox = v1 * v2 * v3\n",
    "\n",
    "        v11 , v22 , v33  = EDATA.shape\n",
    "        nvox2 = v11 * v22 * v33\n",
    "\n",
    "\n",
    "\n",
    "        Parcpet_gm = np.multiply(Parcpet , GM_pet) \n",
    "\n",
    "        Parcpet_re = Parcpet_gm.reshape((nvox2, 1),order='F')\n",
    "        parcindpet = np.unique(Parcpet)\n",
    "        parcindpet = parcindpet[1:]\n",
    "        parcindpet_gm = np.unique(Parcpet_re)\n",
    "        parcindpet_gm = parcindpet_gm[1:]\n",
    "        nroispet = len(np.unique(Parcpet_gm)) - 1\n",
    "\n",
    "        # parcellation on Energy data:\n",
    "        edata_re = EDATA.reshape((nvox2, 1),order='F')\n",
    "\n",
    "        for i in range(nrois_rem):\n",
    "\n",
    "            if parcindpet_gm.__contains__(parcindpet[remain_rois[i]]):\n",
    "\n",
    "                indpet = np.where(Parcpet_re == parcindpet[remain_rois[i]])[0]\n",
    "                data_input['edata_medianallsub'][i, b] = np.nanmedian(edata_re[indpet])\n",
    "            else:\n",
    "\n",
    "                data_input['edata_medianallsub'][i, b] = np.nan\n",
    "        [data_input['num_voxels'][:,b],data_input['MIconn_allsub'][:,:,b],data_input['Pearconn_allsub'][:,:,b]] = conn_mat_EI_new(BDATA, nvox, nT, Parcfmri, GM_fmri, 1, 2, 1, limb_ind) \n",
    "        \n",
    "    data_input['num_voxels'] = np.delete(data_input['num_voxels'] , limb_ind, axis = 0)   \n",
    "\n",
    "    \n",
    "    if session == \"AUF\":\n",
    "        SCconn_allsub = structural_conn(DIR, sub, nrois)\n",
    "    else:\n",
    "        SCconn_allsub = np.ones_like(MIconn_allsub)\n",
    "\n",
    "    data_input['SCconn_allsub'] = SCconn_allsub\n",
    " \n",
    "    return data_input\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structural_conn(DIR, sub, nrois):    \n",
    "\n",
    "    \n",
    "    #sub = [3,7,12,14,17,20,23,25,26,28,29,30,31,33,35,36,37,38];  #***with subcortical******\n",
    "    # downloading SC matrices:\n",
    "    SCconn_allsub = np.zeros((nrois, nrois, len(sub)))\n",
    "    for j in range(len(sub)):\n",
    "        subject = sub[j]\n",
    "        DIR1 = os.path.join(DIR, f'sub-{subject:03}')\n",
    "        #sc_dir = os.path.join(DIR1, 'connectom_glasser_subcortical.csv') #***with subcortical******\n",
    "        sc_dir = os.path.join(DIR1, 'scmat.csv')\n",
    "        scmat = pd.read_csv(sc_dir, header=None)\n",
    "        scmat = scmat.iloc[1:, 1:].to_numpy().astype(float)\n",
    "        if scmat.shape[0] < 360:\n",
    "            print(j)\n",
    "            continue\n",
    "        SCconn_allsub[:, :, j] = scmat\n",
    "\n",
    "\n",
    "    SCconn_allsub = np.delete(SCconn_allsub, limb_ind , axis =0)\n",
    "    SCconn_allsub = np.delete(SCconn_allsub , limb_ind, axis =1)\n",
    "    \n",
    "    return SCconn_allsub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding mvMI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Functional_conn_mvmi(DIR, sub, limb_ind, nrois):\n",
    "    \n",
    "    data_input = {}\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    #sub = [3,7,12,14,17,20,23,25,26,28,29,30,31,32,33,35,36,37,38]; \n",
    "    #sub = [3,7,12,14,17,20,23,25,26,28,29,30,31,33,35,36,37,38]; \n",
    "\n",
    "    #subcor = 15 #***with subcortical******\n",
    "    subcor = 0\n",
    "    remain_rois = range(0 , nrois)\n",
    "    remain_rois = np.delete(remain_rois , limb_ind)\n",
    "    nrois_rem = nrois - len(limb_ind)\n",
    "    mask_rois = np.zeros((nrois, len(sub)))\n",
    "    rois_remain = np.zeros((nrois_rem, len(sub)))\n",
    "\n",
    "    data_input['num_voxels'] = np.zeros((nrois, len(sub) ))\n",
    "    data_input['edata_medianallsub'] = np.zeros((nrois_rem, len(sub) ))\n",
    "    \n",
    "    data_input['MIconn_allsub'] = np.zeros((nrois_rem, nrois_rem, len(sub) ))\n",
    "    data_input['Pearconn_allsub'] = np.zeros((nrois_rem, nrois_rem, len(sub) ))\n",
    "\n",
    "\n",
    "    for b ,subject in enumerate(sub):\n",
    "        \n",
    "        #loading the GM and parcellation in pet and fmri spaces\n",
    "\n",
    "        DIR1 = f'{DIR}sub-{subject:03}/'\n",
    "        Parcfmri =  nib.load(f'{DIR1}/MMP_in_func3mm.nii.gz').get_fdata()\n",
    "        #Parcfmri_subcor =  40 * nib.load(DIR1 + 'mmp_subcortical_in_func3mm.nii.gz').get_fdata()\n",
    "        #Parcfmri_subcor_mask =  nib.load(DIR1 + 'mmp_subcortical_in_func3mm_mask.nii.gz').get_fdata()\n",
    "\n",
    "\n",
    "        Parcpet  =  nib.load(DIR1 + 'MMP_in_pet3mm.nii.gz').get_fdata()\n",
    "        #Parcpet_subcor  =  40 * nib.load(DIR1 + 'mmp_subcortical_in_pet3mm.nii.gz').get_fdata()\n",
    "        #Parcpet_subcor_mask =  nib.load(DIR1 + 'mmp_subcortical_in_pet3mm_mask.nii.gz').get_fdata()\n",
    "\n",
    "\n",
    "        GM_fmri  =  nib.load(DIR1 + \"gm_in_func3mm.nii.gz\").get_fdata()\n",
    "        GM_pet   =  nib.load(DIR1 + \"gm_in_pet3mm.nii.gz\").get_fdata()    \n",
    "\n",
    "\n",
    "        #for adding subcortical regions uncomment the 4 following lines:\n",
    "\n",
    "        #indic_func = -Parcfmri_subcor_mask+1\n",
    "        #indic_pet  = -Parcpet_subcor_mask+1\n",
    "        #Parcfmri  =   np.multiply(indic_func,Parcfmri) + Parcfmri_subcor #***with subcortical******\n",
    "        #Parcpet =  np.multiply(indic_pet , Parcpet)  + Parcpet_subcor #***with subcortical******\n",
    "       # GM_fmri =  GM_fmri + Parcfmri_subcor_mask #***with subcortical******\n",
    "        #GM_pet  =  GM_pet   + Parcpet_subcor_mask #***with subcortical******\n",
    "\n",
    "\n",
    "        #loading the fmri and pet data\n",
    "        BDATA = nib.load(DIR1 + 'func3mm.nii.gz').get_fdata()\n",
    "        EDATA = nib.load(DIR1 + 'pet3mm.nii.gz').get_fdata()\n",
    "\n",
    "        v1, v2, v3, v4 = BDATA.shape\n",
    "        nT = v4\n",
    "        nvox = v1 * v2 * v3\n",
    "\n",
    "        v11 , v22 , v33  = EDATA.shape\n",
    "        nvox2 = v11 * v22 * v33\n",
    "\n",
    "\n",
    "\n",
    "        Parcpet_gm = np.multiply(Parcpet , GM_pet) \n",
    "\n",
    "        Parcpet_re = Parcpet_gm.reshape((nvox2, 1),order='F')\n",
    "        parcindpet = np.unique(Parcpet)\n",
    "        parcindpet = parcindpet[1:]\n",
    "        parcindpet_gm = np.unique(Parcpet_re)\n",
    "        parcindpet_gm = parcindpet_gm[1:]\n",
    "        nroispet = len(np.unique(Parcpet_gm)) - 1\n",
    "\n",
    "        # parcellation on Energy data:\n",
    "        edata_re = EDATA.reshape((nvox2, 1),order='F')\n",
    "\n",
    "        for i in range(nrois_rem):\n",
    "\n",
    "            if parcindpet_gm.__contains__(parcindpet[remain_rois[i]]):\n",
    "\n",
    "                indpet = np.where(Parcpet_re == parcindpet[remain_rois[i]])[0]\n",
    "                data_input['edata_medianallsub'][i, b] = np.nanmedian(edata_re[indpet])\n",
    "            else:\n",
    "\n",
    "                data_input['edata_medianallsub'][i, b] = np.nan\n",
    "        [data_input['num_voxels'][:,b],data_input['MIconn_allsub'][:,:,b],data_input['Pearconn_allsub'][:,:,b]] = conn_mat_EI_mvmi(BDATA, nvox, nT, Parcfmri, GM_fmri, 1, 2, 1, limb_ind) \n",
    "        \n",
    "    data_input['num_voxels'] = np.delete(data_input['num_voxels'] , limb_ind, axis = 0)   \n",
    " \n",
    "    return data_input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conn_mat_EI_mvmi(data, nvox, nT, Parc1, GM, VOX, num_pcs, ABS, rem_ind):\n",
    "    \n",
    "    if VOX == 1:\n",
    "        \n",
    "        rem_ind = limb_ind;\n",
    "        Parcfmri_gm = np.multiply(Parc1 , GM)\n",
    "        Parcfmri_gm_re = np.reshape(Parcfmri_gm, [nvox, 1],order='F')\n",
    "        parcindfmri_gm = np.unique(Parcfmri_gm_re)\n",
    "        parcindfmri_gm = parcindfmri_gm[1:]\n",
    "        nrois_gm = len(np.unique(Parcfmri_gm)) - 1\n",
    "\n",
    "        Parc1_re = np.reshape(Parc1, [nvox, 1],order='F')\n",
    "        nrois = len(np.unique(Parc1_re)) - 1\n",
    "        nrois_rem = nrois - len(rem_ind)\n",
    "        rois_remain = np.arange(1, nrois+1 )\n",
    "        rois_remain[limb_ind ] = 0  \n",
    "        rois_remain = rois_remain[rois_remain != 0] \n",
    "\n",
    "        data_re = np.reshape(data, [nvox, nT] ,order='F')\n",
    "        Parcindfmri = np.unique(Parc1)\n",
    "        Parcindfmri = Parcindfmri[1:]\n",
    "        DATA_avg = np.zeros([nT, nrois])\n",
    "        num_voxels = np.zeros((nrois))\n",
    "        DATA = {}\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(nrois):\n",
    "\n",
    "            if np.any(Parcfmri_gm_re == Parcindfmri[i]):\n",
    "\n",
    "                ind = np.where(Parcfmri_gm_re == Parcindfmri[i])[0]\n",
    "\n",
    "                dd = data_re[ind, :]\n",
    "\n",
    "                # indremove = np.where(np.all(dd == 0, axis=1))[0]\n",
    "                # dd = np.delete(dd, indremove, axis=0)\n",
    "\n",
    "                # if indremove.size == ind.size:\n",
    "                #     zero_rois[i] = 1\n",
    "\n",
    "                DATA[i] = dd\n",
    "                num_voxels[i] = dd.shape[0]\n",
    "                # edata_median[i, 0] = np.median(edata_re[ind])\n",
    "                DATA_avg[:, i] = np.mean(dd, axis=0)\n",
    "            else:\n",
    "                DATA_avg[:, i] = np.nan \n",
    "                DATA[i] = np.zeros((10,1)) \n",
    "\n",
    "        \n",
    "    else:\n",
    "        DATA_avg = data\n",
    "        #nrois = nvox\n",
    "       # nrois_rem = nrois - len(rem_ind)\n",
    "    \n",
    "    \n",
    "\n",
    "    Pearconn = np.corrcoef(DATA_avg, rowvar=False)\n",
    "    Pearconn = np.delete(Pearconn , rem_ind , axis =0)\n",
    "    Pearconn = np.delete(Pearconn , rem_ind , axis =1)\n",
    "\n",
    "    MVMIconn = np.zeros((nrois_rem, nrois_rem))\n",
    "    MIconn = np.zeros((nrois_rem, nrois_rem))\n",
    "    cDATA_avg = np.transpose(copnorm(np.transpose(DATA_avg)))\n",
    "    np.delete(cDATA_avg, limb_ind)\n",
    "    zero_rois = np.zeros(nrois_rem)\n",
    "    Cdata_abs = {}\n",
    "    Cdata = {}\n",
    "    for i in range(nrois_rem):\n",
    "\n",
    "        X = DATA[ rois_remain[i]-1]\n",
    "        ind = np.where(np.sum(X, axis=0) == 0)[0]\n",
    "        if np.any(X) == True:\n",
    "            X = np.delete(X, ind, axis=0)\n",
    "        else:\n",
    "            zero_rois[i] = 1\n",
    "\n",
    "\n",
    "\n",
    "        quan = np.quantile(num_voxels, [0.25, 0.5, 0.75, 1])\n",
    "        if num_voxels[rois_remain[i]-1] > quan[2]:\n",
    "            num_pcs = 5\n",
    "        elif num_voxels[rois_remain[i]-1] > quan[1]:\n",
    "            num_pcs = 4\n",
    "        elif num_voxels[rois_remain[i]-1] > quan[0]:\n",
    "            num_pcs = 3\n",
    "        else:\n",
    "            num_pcs = 2\n",
    "\n",
    "\n",
    "        pca = PCA()\n",
    "        X_score = pca.fit_transform(np.transpose(X))\n",
    "        CC = copnorm(X_score[:, 0:min(num_pcs, X_score.shape[1])].T)\n",
    "        Cdata_abs[i] = np.hstack((CC, copnorm(np.abs(CC))))\n",
    "        Cdata[i] = CC\n",
    "\n",
    "    for i in range(nrois_rem):\n",
    "\n",
    "        if zero_rois[i]==1:\n",
    "            MIconn[i,:]=np.nan\n",
    "            MVMIconn[i,:]=np.nan\n",
    "            continue\n",
    "\n",
    "        CX = Cdata[i]\n",
    "        CX2 = Cdata_abs[i]\n",
    "\n",
    "        for j in range(i+1, nrois_rem):\n",
    "\n",
    "            if zero_rois[j]==1:\n",
    "                MIconn[:,j]=np.nan\n",
    "                MVMIconn[:,j]=np.nan\n",
    "                continue\n",
    "\n",
    "            MIconn[j,i]= mi_gg(cDATA_avg[:,rois_remain[j]-1],cDATA_avg[:,rois_remain[i]-1])  \n",
    "\n",
    "            CY = Cdata[j]     \n",
    "            CY2 = Cdata_abs[j]\n",
    "\n",
    "            if ABS == 1:\n",
    "                num = min(CX2.shape[1], CY2.shape[1])\n",
    "                MVMIconn[i,j] = mi_gg(CX2[:, :num], CY2[:, :num])\n",
    "            else:\n",
    "                MVMIconn[i,j] = mi_gg(CX, CY)\n",
    "\n",
    "\n",
    "    MIconn = MIconn + MIconn.T\n",
    "    \n",
    "    \n",
    "            \n",
    "     \n",
    "    MVMIconn = MVMIconn + MVMIconn.T\n",
    "\n",
    "    return num_voxels  , MIconn , Pearconn, MVMIconn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steiger_z_test(r12, r13, r23, n):\n",
    "    \"\"\"\n",
    "    Performs Steiger's Z-test to compare two dependent correlation coefficients.\n",
    "\n",
    "    Parameters:\n",
    "        r12 (float): Correlation between variable 1 and 2.\n",
    "        r13 (float): Correlation between variable 1 and 3.\n",
    "        r23 (float): Correlation between variable 2 and 3.\n",
    "        n (int): Sample size.\n",
    "\n",
    "    Returns:\n",
    "        z (float): Z-score.\n",
    "        p (float): Two-tailed p-value.\n",
    "    \"\"\"\n",
    "    # Fisher transformation for r12 and r13\n",
    "    z12 = 0.5 * np.log((1 + r12) / (1 - r12))\n",
    "    z13 = 0.5 * np.log((1 + r13) / (1 - r13))\n",
    "\n",
    "    # Compute standard error\n",
    "    se = np.sqrt((2 * (1 - r23)) / (n - 3))\n",
    "\n",
    "    # Compute Steiger's Z-score\n",
    "    z = (z12 - z13) / se\n",
    "\n",
    "    # Compute two-tailed p-value\n",
    "    p = 2 * (1 - norm.cdf(abs(z)))\n",
    "\n",
    "    return z, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_node_surf(data, conn_mat, param, CMAP, edge_thr, limb_ind):\n",
    " \n",
    "    cmat = np.mean(conn_mat, axis=2)\n",
    "\n",
    "\n",
    "    plotly_cmap = [\n",
    "        [f, '#{:02x}{:02x}{:02x}'.format(*((rgba[:3] * 255).astype(int)))]\n",
    "        for f, rgba in zip(np.linspace(0, 1, 256), CMAP(np.linspace(0, 1, 256)))\n",
    "    ]\n",
    "\n",
    "\n",
    "    IC = data[param].values.astype(float)\n",
    "    IC_min = IC.min()\n",
    "    cap = 34 if param == \"ICallsub_w_avg\" else IC.max()\n",
    "    IC_capped = np.clip(IC, IC_min, cap)\n",
    "    IC_norm = IC\n",
    "    color_values = IC_capped\n",
    "\n",
    "\n",
    "    coords = pd.read_csv(\"/data/external/HCP-MMP1_UniqueRegionList.csv\")\n",
    "    coords = coords[[\"x-cog\", \"y-cog\", \"z-cog\"]]\n",
    "    coords_df = coords.drop(limb_ind, axis=0)\n",
    "    coords_df.columns = coords_df.columns.str.strip()\n",
    "    nodes = coords_df[['x-cog', 'y-cog', 'z-cog']].values\n",
    "\n",
    "   \n",
    "    G = nx.Graph()\n",
    "    for idx, node in enumerate(nodes):\n",
    "        G.add_node(idx, coord=node)\n",
    "    source, target = np.nonzero(np.triu(cmat) > edge_thr)\n",
    "    edges = list(zip(source, target))\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    nodes_x = coords_df['x-cog'].values\n",
    "    nodes_y = coords_df['y-cog'].values\n",
    "    nodes_z = coords_df['z-cog'].values\n",
    "\n",
    "    p85, p90, p95 = np.percentile(IC_norm, [85, 90, 95])\n",
    "    node_sizes = np.full_like(IC_norm, 8, dtype=np.float32)\n",
    "    node_sizes[IC_norm >= p85] = 12\n",
    "    node_sizes[IC_norm >= p90] = 17\n",
    "    node_sizes[IC_norm >= p95] = 22\n",
    "\n",
    "    edge_x, edge_y, edge_z = [], [], []\n",
    "    for s, t in edges:\n",
    "        edge_x += [nodes_x[s], nodes_x[t], None]\n",
    "        edge_y += [nodes_y[s], nodes_y[t], None]\n",
    "        edge_z += [nodes_z[s], nodes_z[t], None]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- nodes\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=nodes_x, y=nodes_y, z=nodes_z, mode='markers', name='Nodes',\n",
    "        marker=dict(size=node_sizes, color=color_values, colorscale=plotly_cmap,\n",
    "                    opacity=0.8, showscale=False),\n",
    "        showlegend=False, hoverinfo='text'\n",
    "    ))\n",
    "\n",
    "    # --- edges\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=edge_x, y=edge_y, z=edge_z, mode='lines', name='Edges',\n",
    "        line=dict(color='gray'), opacity=0.1, showlegend=False, hoverinfo='none'\n",
    "    ))\n",
    "\n",
    "\n",
    "    logical_sizes = [8, 12, 17, 22]\n",
    "    labels = [\"≤ 85th pct\", \"≥ 85th pct\", \"≥ 90th pct\", \"≥ 95th pct\"]\n",
    "\n",
    "   \n",
    "    leg_min, leg_max = 6.0, 15.0\n",
    "    s_min, s_max = min(logical_sizes), max(logical_sizes)\n",
    "    legend_sizes = [leg_min + (s - s_min) * (leg_max - leg_min) / (s_max - s_min)\n",
    "                    for s in logical_sizes]\n",
    "\n",
    "    size_levels = np.array([8, 12, 17, 22], dtype=float)   # your original tiers\n",
    "\n",
    "    # pick a global scale so the figure isn't crowded (tweak 0.55–0.8 to taste)\n",
    "    size_scale = 0.65\n",
    "    size_levels_scaled = (size_levels * size_scale).tolist()\n",
    "    \n",
    "    # thresholds\n",
    "    p85, p90, p95 = np.percentile(IC_norm, [85, 90, 95])\n",
    "    \n",
    "    # apply to nodes (now nodes and legend will be identical in pixels)\n",
    "    node_sizes = np.full_like(IC_norm, size_levels_scaled[0], dtype=float)\n",
    "    node_sizes[IC_norm >= p85] = size_levels_scaled[1]\n",
    "    node_sizes[IC_norm >= p90] = size_levels_scaled[2]\n",
    "    node_sizes[IC_norm >= p95] = size_levels_scaled[3]\n",
    "\n",
    "\n",
    "  \n",
    "    for label, s in zip(labels, legend_sizes):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[None], y=[None], mode=\"markers\", name=label, hoverinfo=\"skip\", showlegend=True,\n",
    "            marker=dict(size=s, color=\"rgba(128,128,128,0.9)\", line=dict(color=\"gray\", width=1)),\n",
    "            legendgroup=\"size\",\n",
    "        ))\n",
    "\n",
    "    \n",
    "    # --- orientation, background, and tight legend placement ---\n",
    "    fig.update_layout(\n",
    "        # fill the canvas; leave a slim band for the legend\n",
    "        scene=dict(\n",
    "            bgcolor=\"white\",\n",
    "            xaxis=dict(visible=False),\n",
    "            yaxis=dict(visible=False),\n",
    "            zaxis=dict(visible=False),\n",
    "            aspectmode=\"data\",\n",
    "            domain=dict(y=[0.12, 1.0])   # push the 3D scene up; ~12% space for legend\n",
    "        ),\n",
    "        scene_camera=dict(\n",
    "            eye=dict(x=0.0, y=1.8, z=0.08),  # frontal view; smaller values = more zoom\n",
    "            up=dict(x=0, y=0, z=1),\n",
    "            center=dict(x=0, y=0, z=0),\n",
    "        ),\n",
    "    \n",
    "        # legend right below the scene, centered\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            itemsizing=\"trace\",\n",
    "            x=0.5, xanchor=\"center\",\n",
    "            y=0.15, yanchor=\"top\"          # sits just under the scene\n",
    "        ),\n",
    "    \n",
    "        # remove blue page background\n",
    "        paper_bgcolor=\"white\",\n",
    "        plot_bgcolor=\"white\",\n",
    "    \n",
    "        width=900, height=900,\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "    \n",
    "        # hide the 2D axes created by legend dummies\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # --- save (requires 'kaleido'); comment out if not installed\n",
    "    # fig.write_image(f'Figures/node_surface_{param}.png', scale=3)\n",
    "    fig.show()\n",
    "\n",
    "    print(\"Original number of regions:\", coords.shape[0])\n",
    "    print(\"Removed limb regions:\", len(limb_ind))\n",
    "    print(\"Remaining plotted regions:\", len(nodes_x))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GL neuroenergeticslab2024 py3.11",
   "language": "python",
   "name": "neuroenergeticslab2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
